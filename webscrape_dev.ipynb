{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_26076\\894987728.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def scrape_batting_table(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_team_tables(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Function to perform the scraping\n",
    "def scrape_page(url, scrape_func):\n",
    "    \"\"\"Scrape the CCBC website for a given url and scrape_func\n",
    "\n",
    "    Args:\n",
    "        url (str): The url to scrape\n",
    "        scrape_func (function): The function to use to scrape the table\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the scraped data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(url)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the select element with the id seasonid\n",
    "    select = soup.find('select', {'id': 'seasonid'})\n",
    "    # Get the options from the select element (this is the list of years)\n",
    "    options = select.find_all('option')\n",
    "    # Create a dictionary of the years (seasons) with the season_id as the key and the season name as the value\n",
    "    seasons = {option['value']: option.text for option in options}\n",
    "    print(seasons)\n",
    "    \n",
    "    # For season in season_ids scrape the table and append the results to a dataframe using the scrape_func\n",
    "    df = pd.DataFrame()\n",
    "    for season in seasons.keys():\n",
    "        temp_df = scrape_func(season)\n",
    "        # append the new row to the DataFrame\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    # Create a new variable called season that uses the season_id column to look up the season name in the seasons dictionary\n",
    "    df['season'] = df['season_id'].map(seasons)\n",
    "\n",
    "    # Drop the season_id column\n",
    "    df.drop('season_id', axis=1, inplace=True)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "def scrape_pitching_table(season_id):\n",
    "    \"\"\"Scrape the pitching table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the pitching table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The pitching table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teampitching'\n",
    "\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitch_first > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_standings_table(season_id):\n",
    "    \"\"\"Scrape the standings table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the standings table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The standings table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/standings.html?{season_id}&stype=l'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#psbb_standings > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_batters_table(season_id):\n",
    "    \"\"\"Scrape the qualified batters table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified batters table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified batters table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=batting'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#battingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_pitchers_table(season_id):\n",
    "    \"\"\"Scrape the qualified pitchers table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified pitchers table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified pitchers table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=pitching'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitchingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>P</th>\n",
       "      <th>AVG</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>...</th>\n",
       "      <th>BB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SO</th>\n",
       "      <th>SF</th>\n",
       "      <th>SH</th>\n",
       "      <th>SB</th>\n",
       "      <th>CS</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>season_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morris, B</td>\n",
       "      <td>IF</td>\n",
       "      <td>.342</td>\n",
       "      <td>31</td>\n",
       "      <td>117</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robertson, J</td>\n",
       "      <td>OF</td>\n",
       "      <td>.333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bourget, R</td>\n",
       "      <td>OF</td>\n",
       "      <td>.327</td>\n",
       "      <td>31</td>\n",
       "      <td>107</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Popik, T</td>\n",
       "      <td>OF</td>\n",
       "      <td>.273</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Browning, D</td>\n",
       "      <td>IF</td>\n",
       "      <td>.256</td>\n",
       "      <td>24</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player   P   AVG   G   AB   R   H  2B 3B HR  ...  BB HBP  SO SF SH  \\\n",
       "0     Morris, B  IF  .342  31  117  20  40   4  2  1  ...  15   3  17  1  0   \n",
       "1  Robertson, J  OF  .333   3    3   0   1   0  0  0  ...   0   0   1  0  0   \n",
       "2    Bourget, R  OF  .327  31  107  32  35  10  1  2  ...  14   6  23  2  1   \n",
       "3      Popik, T  OF  .273  14   22   3   6   0  0  0  ...   4   6   7  0  0   \n",
       "4   Browning, D  IF  .256  24   82  15  21   3  0  0  ...  11   4  15  1  1   \n",
       "\n",
       "   SB CS DP   E season_id  \n",
       "0  19  4  1  10     33653  \n",
       "1   0  0  0   0     33653  \n",
       "2  11  3  3   4     33653  \n",
       "3   1  0  0   3     33653  \n",
       "4   5  3  1   4     33653  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_team_batting(season_id, team_id):\n",
    "    \"\"\"Scrape the team batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the team batting table for (this is the year)\n",
    "        team_id (str): The team_id to scrape the team batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The team batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'https://baseball.pointstreak.com/team_stats.html?teamid={team_id}&seasonid={season_id}'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    \n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    table = soup.find('table', class_ = 'table table-hover table-striped nova-stats-table nova-stats-table--fixed-first-col')\n",
    "    'table table-hover table-striped nova-stats-table nova-stats-table--fixed-first-col'\n",
    "\n",
    "    # Fail Safe if no table is found\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    \n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table.find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "season_id = '33653'\n",
    "team_id = '142674'\n",
    "\n",
    "test_df = scrape_team_batting(season_id, team_id)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
