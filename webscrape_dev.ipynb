{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def scrape_batting_table(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_team_tables(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Function to perform the scraping\n",
    "def scrape_page(url, scrape_func):\n",
    "    \"\"\"Scrape the CCBC website for a given url and scrape_func\n",
    "\n",
    "    Args:\n",
    "        url (str): The url to scrape\n",
    "        scrape_func (function): The function to use to scrape the table\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the scraped data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(url)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the select element with the id seasonid\n",
    "    select = soup.find('select', {'id': 'seasonid'})\n",
    "    # Get the options from the select element (this is the list of years)\n",
    "    options = select.find_all('option')\n",
    "    # Create a dictionary of the years (seasons) with the season_id as the key and the season name as the value\n",
    "    seasons = {option['value']: option.text for option in options}\n",
    "    print(seasons)\n",
    "    \n",
    "    # For season in season_ids scrape the table and append the results to a dataframe using the scrape_func\n",
    "    df = pd.DataFrame()\n",
    "    for season in seasons.keys():\n",
    "        temp_df = scrape_func(season)\n",
    "        # append the new row to the DataFrame\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    # Create a new variable called season that uses the season_id column to look up the season name in the seasons dictionary\n",
    "    df['season'] = df['season_id'].map(seasons)\n",
    "\n",
    "    # Drop the season_id column\n",
    "    df.drop('season_id', axis=1, inplace=True)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "def scrape_pitching_table(season_id):\n",
    "    \"\"\"Scrape the pitching table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the pitching table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The pitching table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teampitching'\n",
    "\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitch_first > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_standings_table(season_id):\n",
    "    \"\"\"Scrape the standings table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the standings table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The standings table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/standings.html?{season_id}&stype=l'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#psbb_standings > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_batters_table(season_id):\n",
    "    \"\"\"Scrape the qualified batters table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified batters table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified batters table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=batting'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#battingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_pitchers_table(season_id):\n",
    "    \"\"\"Scrape the qualified pitchers table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified pitchers table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified pitchers table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=pitching'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitchingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
