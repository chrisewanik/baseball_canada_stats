{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_26076\\894987728.py:4: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "def scrape_batting_table(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_team_tables(season_id):\n",
    "    \"\"\"Scrape the batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teambatting'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#bat_first > table:nth-child(1)')\n",
    "    \n",
    "    # Check if the table is empty\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers (th) from the table\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "    \n",
    "    # Get the rows (tr) from the table\n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data (td) from the row\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "\n",
    "\n",
    "# %%\n",
    "# Function to perform the scraping\n",
    "def scrape_page(url, scrape_func):\n",
    "    \"\"\"Scrape the CCBC website for a given url and scrape_func\n",
    "\n",
    "    Args:\n",
    "        url (str): The url to scrape\n",
    "        scrape_func (function): The function to use to scrape the table\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The dataframe containing the scraped data\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(url)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the select element with the id seasonid\n",
    "    select = soup.find('select', {'id': 'seasonid'})\n",
    "    # Get the options from the select element (this is the list of years)\n",
    "    options = select.find_all('option')\n",
    "    # Create a dictionary of the years (seasons) with the season_id as the key and the season name as the value\n",
    "    seasons = {option['value']: option.text for option in options}\n",
    "    print(seasons)\n",
    "    \n",
    "    # For season in season_ids scrape the table and append the results to a dataframe using the scrape_func\n",
    "    df = pd.DataFrame()\n",
    "    for season in seasons.keys():\n",
    "        temp_df = scrape_func(season)\n",
    "        # append the new row to the DataFrame\n",
    "        df = pd.concat([df, temp_df])\n",
    "\n",
    "    # Create a new variable called season that uses the season_id column to look up the season name in the seasons dictionary\n",
    "    df['season'] = df['season_id'].map(seasons)\n",
    "\n",
    "    # Drop the season_id column\n",
    "    df.drop('season_id', axis=1, inplace=True)\n",
    "    \n",
    "    # Return the dataframe\n",
    "    return df\n",
    "\n",
    "def scrape_pitching_table(season_id):\n",
    "    \"\"\"Scrape the pitching table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the pitching table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The pitching table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=teampitching'\n",
    "\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitch_first > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        # Check if the row is empty if not append the season_id to the row and append the row to the rows list\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_standings_table(season_id):\n",
    "    \"\"\"Scrape the standings table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the standings table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The standings table for the given season_id\n",
    "    \"\"\"    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/standings.html?{season_id}&stype=l'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#psbb_standings > table:nth-child(1)')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_batters_table(season_id):\n",
    "    \"\"\"Scrape the qualified batters table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified batters table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified batters table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=batting'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#battingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "def scrape_qual_pitchers_table(season_id):\n",
    "    \"\"\"Scrape the qualified pitchers table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the qualified pitchers table for (this is the year)\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The qualified pitchers table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'http://pointstreak.com/baseball/stats.html?{season_id}&view=pitching'\n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    # Get the table\n",
    "    table = soup.select('#pitchingresults')\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table[0].find_all('th')]\n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table[0].find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>P</th>\n",
       "      <th>AVG</th>\n",
       "      <th>G</th>\n",
       "      <th>AB</th>\n",
       "      <th>R</th>\n",
       "      <th>H</th>\n",
       "      <th>2B</th>\n",
       "      <th>3B</th>\n",
       "      <th>HR</th>\n",
       "      <th>...</th>\n",
       "      <th>BB</th>\n",
       "      <th>HBP</th>\n",
       "      <th>SO</th>\n",
       "      <th>SF</th>\n",
       "      <th>SH</th>\n",
       "      <th>SB</th>\n",
       "      <th>CS</th>\n",
       "      <th>DP</th>\n",
       "      <th>E</th>\n",
       "      <th>season_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Morris, B</td>\n",
       "      <td>IF</td>\n",
       "      <td>.342</td>\n",
       "      <td>31</td>\n",
       "      <td>117</td>\n",
       "      <td>20</td>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Robertson, J</td>\n",
       "      <td>OF</td>\n",
       "      <td>.333</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bourget, R</td>\n",
       "      <td>OF</td>\n",
       "      <td>.327</td>\n",
       "      <td>31</td>\n",
       "      <td>107</td>\n",
       "      <td>32</td>\n",
       "      <td>35</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Popik, T</td>\n",
       "      <td>OF</td>\n",
       "      <td>.273</td>\n",
       "      <td>14</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Browning, D</td>\n",
       "      <td>IF</td>\n",
       "      <td>.256</td>\n",
       "      <td>24</td>\n",
       "      <td>82</td>\n",
       "      <td>15</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>33653</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Player   P   AVG   G   AB   R   H  2B 3B HR  ...  BB HBP  SO SF SH  \\\n",
       "0     Morris, B  IF  .342  31  117  20  40   4  2  1  ...  15   3  17  1  0   \n",
       "1  Robertson, J  OF  .333   3    3   0   1   0  0  0  ...   0   0   1  0  0   \n",
       "2    Bourget, R  OF  .327  31  107  32  35  10  1  2  ...  14   6  23  2  1   \n",
       "3      Popik, T  OF  .273  14   22   3   6   0  0  0  ...   4   6   7  0  0   \n",
       "4   Browning, D  IF  .256  24   82  15  21   3  0  0  ...  11   4  15  1  1   \n",
       "\n",
       "   SB CS DP   E season_id  \n",
       "0  19  4  1  10     33653  \n",
       "1   0  0  0   0     33653  \n",
       "2  11  3  3   4     33653  \n",
       "3   1  0  0   3     33653  \n",
       "4   5  3  1   4     33653  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def scrape_team_batting(season_id, team_id):\n",
    "    \"\"\"Scrape the team batting table from the CCBC website for a given season_id\n",
    "\n",
    "    Args:\n",
    "        season_id (str): The season_id to scrape the team batting table for (this is the year)\n",
    "        team_id (str): The team_id to scrape the team batting table for\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The team batting table for the given season_id\n",
    "    \"\"\"    \n",
    "    \n",
    "    # Create the path string using the season_id\n",
    "    path = f'https://baseball.pointstreak.com/team_stats.html?teamid={team_id}&seasonid={season_id}'\n",
    "    \n",
    "    # Get the page\n",
    "    page = requests.get(path)\n",
    "    \n",
    "    # Create the soup object\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    # Find the table\n",
    "    table = soup.find('table', class_ = 'table table-hover table-striped nova-stats-table nova-stats-table--fixed-first-col')\n",
    "\n",
    "    # Fail Safe if no table is found\n",
    "    if not table:\n",
    "        print(f'No table found for season_id {season_id}')\n",
    "        return None\n",
    "    \n",
    "    # Get the headers from the table (th)\n",
    "    headers = [th.text.strip() for th in table.find_all('th')]\n",
    "    \n",
    "    # Add the season_id to the headers\n",
    "    headers.append('season_id')\n",
    "    \n",
    "    # Create an empty list to store the rows\n",
    "    rows = []\n",
    "\n",
    "    # Get the rows from the table (tr)    \n",
    "    for tr in table.find_all('tr'):\n",
    "        # Get the data from the row (td)\n",
    "        row = [td.text.strip() for td in tr.find_all('td')]\n",
    "        if row:\n",
    "            row.append(season_id)\n",
    "            rows.append(row)\n",
    "    return pd.DataFrame(rows, columns=headers)\n",
    "\n",
    "season_id = '33653'\n",
    "team_id = '142674'\n",
    "\n",
    "test_df = scrape_team_batting(season_id, team_id)\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_page(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    nav = soup.find('ul', {'class': 'list-unstyled nav navbar-nav'})  # adjust this to find the correct list\n",
    "\n",
    "    data = []\n",
    "    for li in nav.find_all('li', {'class': 'nova-list-item'}):\n",
    "        link = li.find('a', href=True)\n",
    "        if 'Stats' in link.text:\n",
    "            stats_url = 'https://baseball.pointstreak.com/' + link['href']\n",
    "            stats_response = requests.get(stats_url)\n",
    "            stats_soup = BeautifulSoup(stats_response.text, 'html.parser')\n",
    "            # Scrape the stats and append them to data\n",
    "\n",
    "    # df = pd.DataFrame(data)\n",
    "\n",
    "    return None\n",
    "\n",
    "urls = ['https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653']  # list of URLs to scrape\n",
    "dfs = [scrape_page(url) for url in urls]\n",
    "df = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Edmonton Collegiate\n",
      "Okanagan College\n",
      "Prairie Baseball Academy\n",
      "Thompson Rivers University\n",
      "University of Calgary\n",
      "University of Fraser Valley\n",
      "Vancouver Island University\n",
      "Victoria Collegiate\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_team_names(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_list = soup.find('ul', {'class': 'ps_teamlist list-unstyled'})\n",
    "\n",
    "    for li in team_list.find_all('li'):\n",
    "        link = li.find('a', href=True)\n",
    "        if link is not None:\n",
    "            print(link.text)\n",
    "\n",
    "print_team_names('https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142674&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142669&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142670&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142668&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142671&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142672&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=142673&seasonid=33653\n",
      "Page accessed\n",
      "Accessing page: https://baseball.pointstreak.com/team_home.html?teamid=157388&seasonid=33653\n",
      "Page accessed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_team_names(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_list = soup.find('ul', {'class': 'ps_teamlist list-unstyled'})\n",
    "\n",
    "    for li in team_list.find_all('li'):\n",
    "        link = li.find('a', href=True)\n",
    "        if link is not None:\n",
    "            team_url = 'https://baseball.pointstreak.com/' + link['href']\n",
    "            print(f\"Accessing page: {team_url}\")\n",
    "            team_response = requests.get(team_url)\n",
    "            # You can add code here to do something with the team page\n",
    "            print(\"Page accessed\")\n",
    "\n",
    "print_team_names('https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142674&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142674&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142669&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142669&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142670&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142670&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142668&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142668&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142671&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142671&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142672&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142672&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142673&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142673&seasonid=33653\n",
      "Stats page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=157388&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=157388&seasonid=33653\n",
      "Stats page accessed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def print_team_names(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_list = soup.find('ul', {'class': 'ps_teamlist list-unstyled'})\n",
    "\n",
    "    for li in team_list.find_all('li'):\n",
    "        link = li.find('a', href=True)\n",
    "        if link is not None:\n",
    "            team_url = 'https://baseball.pointstreak.com/' + link['href']\n",
    "            print(f\"Accessing team page: {team_url}\")\n",
    "            team_response = requests.get(team_url)\n",
    "            team_soup = BeautifulSoup(team_response.text, 'html.parser')\n",
    "            nav = team_soup.find('ul', {'class': 'list-unstyled nav navbar-nav'})\n",
    "            if nav is not None:\n",
    "                stats_link = None\n",
    "                for item in nav.find_all('li', {'class': 'nova-list-item'}):\n",
    "                    link = item.find('a', href=True)\n",
    "                    if link is not None and 'Stats' in link.text:\n",
    "                        stats_link = link\n",
    "                        break\n",
    "                if stats_link is not None:\n",
    "                    stats_url = 'https://baseball.pointstreak.com/' + stats_link['href']\n",
    "                    print(f\"Accessing stats page: {stats_url}\")\n",
    "                    stats_response = requests.get(stats_url)\n",
    "                    print(\"Stats page accessed\")\n",
    "\n",
    "print_team_names('https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142674&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142674&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142674&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142669&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142669&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142669&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142670&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142670&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142670&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142668&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142668&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142668&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142671&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142671&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142671&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142672&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142672&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142672&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142673&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142673&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142673&seasonid=33653&view=batting\n",
      "Print page accessed\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=157388&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=157388&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=157388&seasonid=33653&view=batting\n",
      "Print page accessed\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def access_print_page(url):\n",
    "    print_url = 'https://baseball.pointstreak.com/' + url\n",
    "    print(f\"Accessing print page: {print_url}\")\n",
    "    print_response = requests.get(print_url)\n",
    "    print(\"Print page accessed\")\n",
    "\n",
    "def access_team_stats_pages(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_list = soup.find('ul', {'class': 'ps_teamlist list-unstyled'})\n",
    "\n",
    "    for li in team_list.find_all('li'):\n",
    "        link = li.find('a', href=True)\n",
    "        if link is not None:\n",
    "            team_url = 'https://baseball.pointstreak.com/' + link['href']\n",
    "            print(f\"Accessing team page: {team_url}\")\n",
    "            team_response = requests.get(team_url)\n",
    "            team_soup = BeautifulSoup(team_response.text, 'html.parser')\n",
    "            nav = team_soup.find('ul', {'class': 'list-unstyled nav navbar-nav'})\n",
    "            if nav is not None:\n",
    "                stats_link = None\n",
    "                for item in nav.find_all('li', {'class': 'nova-list-item'}):\n",
    "                    link = item.find('a', href=True)\n",
    "                    if link is not None and 'Stats' in link.text:\n",
    "                        stats_link = link\n",
    "                        break\n",
    "                if stats_link is not None:\n",
    "                    stats_url = 'https://baseball.pointstreak.com/' + stats_link['href']\n",
    "                    print(f\"Accessing stats page: {stats_url}\")\n",
    "                    stats_response = requests.get(stats_url)\n",
    "                    stats_soup = BeautifulSoup(stats_response.text, 'html.parser')\n",
    "                    print_div = stats_soup.find('div', {'class': 'pull-left'})\n",
    "                    print_link = print_div.find('a', href=True, string='Print')\n",
    "                    if print_link is not None:\n",
    "                        access_print_page(print_link['href'])\n",
    "\n",
    "access_team_stats_pages('https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142674&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142674&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142674&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "edmonton_collegiate\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.edm _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142669&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142669&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142669&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "okanagan_college\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.coyotes _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142670&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142670&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142670&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "prairie_baseball_academy\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.dawgs _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142668&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142668&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142668&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "thompson_rivers_university\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.wolfpack _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142671&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142671&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142671&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "university_of_calgary\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.dinos _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142672&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142672&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142672&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "university_of_fraser_valley\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.cascades _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=142673&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=142673&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=142673&seasonid=33653&view=batting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data stored in DataFrame: \n",
      "\n",
      "vancouver_island_university\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.mariners _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n",
      "Accessing team page: https://baseball.pointstreak.com/team_home.html?teamid=157388&seasonid=33653\n",
      "Accessing stats page: https://baseball.pointstreak.com/team_stats.html?teamid=157388&seasonid=33653\n",
      "Accessing print page: https://baseball.pointstreak.com/printstats.html?teamid=157388&seasonid=33653&view=batting\n",
      "Data stored in DataFrame: \n",
      "\n",
      "victoria_collegiate\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tdivision:_canadian_college_baseball_conf.golden_tide _|_ league:_canadian_college_baseball_conference_(ccbc)ccbc\n",
      "\n",
      "\n",
      "\t\t\t\t\t\t\t\tseason:_ccbc_2023\n",
      "\t\t\t\t\t\t\t\n",
      "_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Chris\\AppData\\Local\\Temp\\ipykernel_7752\\2912203201.py:9: FutureWarning: Passing literal html to 'read_html' is deprecated and will be removed in a future version. To read from a literal string, wrap it in a 'StringIO' object.\n",
      "  dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def access_print_page(url, h2_text):\n",
    "    print_url = 'https://baseball.pointstreak.com/' + url\n",
    "    print(f\"Accessing print page: {print_url}\")\n",
    "    print_response = requests.get(print_url)\n",
    "    dfs = pd.read_html(print_response.text, attrs={'border': '1'})\n",
    "    if dfs:\n",
    "        df = dfs[0]\n",
    "        df.columns = df.iloc[0]\n",
    "        df = df[1:]\n",
    "        df.columns = df.columns.str.lower().str.replace(' ', '_')\n",
    "        df = df[df.player != 'Totals']\n",
    "        df_name = h2_text.lower().replace(' ', '_') + '_df'\n",
    "        globals()[df_name] = df\n",
    "        print(f\"Data stored in DataFrame: {df_name}\")\n",
    "\n",
    "def access_team_stats_pages(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    team_list = soup.find('ul', {'class': 'ps_teamlist list-unstyled'})\n",
    "\n",
    "    for li in team_list.find_all('li'):\n",
    "        link = li.find('a', href=True)\n",
    "        if link is not None:\n",
    "            team_url = 'https://baseball.pointstreak.com/' + link['href']\n",
    "            print(f\"Accessing team page: {team_url}\")\n",
    "            team_response = requests.get(team_url)\n",
    "            team_soup = BeautifulSoup(team_response.text, 'html.parser')\n",
    "            nav = team_soup.find('ul', {'class': 'list-unstyled nav navbar-nav'})\n",
    "            if nav is not None:\n",
    "                stats_link = None\n",
    "                for item in nav.find_all('li', {'class': 'nova-list-item'}):\n",
    "                    link = item.find('a', href=True)\n",
    "                    if link is not None and 'Stats' in link.text:\n",
    "                        stats_link = link\n",
    "                        break\n",
    "                if stats_link is not None:\n",
    "                    stats_url = 'https://baseball.pointstreak.com/' + stats_link['href']\n",
    "                    print(f\"Accessing stats page: {stats_url}\")\n",
    "                    stats_response = requests.get(stats_url)\n",
    "                    stats_soup = BeautifulSoup(stats_response.text, 'html.parser')\n",
    "                    print_div = stats_soup.find('div', {'class': 'pull-left'})\n",
    "                    print_link = print_div.find('a', href=True, string='Print')\n",
    "                    if print_link is not None:\n",
    "                        h2_text = stats_soup.find('h2').text\n",
    "                        access_print_page(print_link['href'], h2_text)\n",
    "\n",
    "access_team_stats_pages('https://baseball.pointstreak.com/teamlist.html?leagueid=160&seasonid=33653')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
